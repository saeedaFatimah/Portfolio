# Saeeda Ramzan's Data Science Portfolio

I am a certified Data Scientist with a robust background in Software Quality Assurance (SQA) and a strong passion for data science. With a BS in Software Engineering from the Virtual University of Pakistan and a Professional Data Analyst Certification from Karachi.AI, I have developed a comprehensive skill set in both quality assurance and data analysis.

During my time as an SQA Engineer, I collaborated with development teams to ensure product quality and reliability. I gained extensive experience in writing test cases, bug tracking, and reporting across multiple platforms, including mobile and web applications. My responsibilities included testing applications across different devices, maintaining test data for accurate results, and managing QA for various projects.

However, my passion for uncovering insights from data and my attraction to the rapidly evolving field of data science led me to pursue further education and certification in this area. Through my intensive certification program, I gained expertise in predictive modeling, statistical analysis, machine learning, data cleaning, preprocessing, time series analysis, recommendation systems, and hypothesis testing. I am proficient in Python and SQL, and I excel at using data visualization tools like Power BI to communicate insights effectively.

I am now eager to leverage my analytical aptitude and data science skills to make meaningful contributions to a dynamic data science team. I am passionate about continuously learning and staying updated with the latest advancements in data science and machine learning.

## About Me
I am a certified data analyst with a strong background in Python programming, statistics, machine learning, SQL, and Tableau. I completed a comprehensive 16-week data analytics certification course from an institute affiliated with FAST University in Karachi. My passion lies in leveraging data to solve complex problems and drive business decisions.

## Skills
- **Programming Languages:** Python, SQL
- **Data Analysis:** pandas, NumPy, Matplotlib, seaborn
- **Machine Learning:** scikit-learn, K-means clustering, decision trees, logistic regression
- **Data Visualization:** Tableau, Matplotlib, seaborn
- **Tools:** Jupyter Notebook, Git, Excel

- - **Email:** saeedaa.fatimah@gmail.com
- - **LinkedIn:** https://www.linkedin.com/in/saeedafatima-ramzanali
- - **DataCamp Portfolio:** [Saeeda Fatimah's DataCamp Portfolio](https://www.datacamp.com/portfolio/saeedaafatimah)
- - **Github Portfolio:** [https://github.com/saeedaFatimah/Portfolio/blob/Portfolio/README.md)

## Projects

### [Employee Churn Prediction]
- **Description:** A project aimed at predicting employee churn using machine learning techniques to identify employees likely to leave the company.
- **Key Activities:**
  - Data Preprocessing: Handled missing values, encoded categorical features, and scaled numerical features.
  - Exploratory Data Analysis (EDA): Visualized feature distributions and relationships, performed correlation analysis.
  - Feature Engineering: Created new features and selected important ones for the model.
  - Model Training: Implemented various algorithms, including Logistic Regression, Decision Trees, and Random Forest, and performed hyperparameter tuning.
  - Model Evaluation: Assessed models using accuracy, precision, recall, F1-score, and ROC-AUC, and used cross-validation to ensure consistency.
- **Skills Used:** Python, pandas, scikit-learn, data visualization.
- **Link to Project:** [Streamlit App for Employee Churn](https://github.com/saeedaFatimah/Portfolio/tree/project-1-StreamLit-App-for-Employee-Churn)

### [Customer Segmentation using RFM Analysis]
- **Description:** A project for segmenting customers based on Recency, Frequency, and Monetary metrics to improve marketing strategies.
- **Key Activities:**
  - Data Preprocessing: Cleaned and prepared customer transaction data.
  - RFM Analysis: Calculated RFM scores for each customer and segmented them into different groups.
  - Visualization: Created visualizations to illustrate customer segments and their characteristics.
  - Clustering: Applied K-means clustering to group customers based on RFM scores.
- **Skills Used:** Python, pandas, clustering algorithms, data visualization.
- **Link to Project:** [RFM-Segmenation over Store dataset](https://github.com/saeedaFatimah/Portfolio/tree/Project-2--RFM-segmentation-over-store-dataset)

### [K-means Clustering for Data Analysis]
- **Description:** Implemented K-means clustering on rfm clusters to analyze and interpret data for better insights.
- **Key Activities:**
  - Data Preprocessing: Cleaned and normalized the data for clustering.
  - Clustering: Applied K-means algorithm to identify clusters in the data.
  - Visualization: Visualized the resulting clusters using scatter plots and other visual aids.
  - Interpretation: Analyzed cluster characteristics and derived meaningful insights.
- **Skills Used:** Python, scikit-learn, matplotlib, pandas.
- **Link to Project:**  [ML clustering over RFM segmentation ](https://github.com/saeedaFatimah/Portfolio/tree/Project-2--RFM-segmentation-over-store-dataset)

### [Olympic Athlete Data Analysis]

**Objective:** Analyze Olympic athlete data to uncover trends and insights related to athlete attributes and regional differences.

**Key Insights**
Data Cleaning and Preparation:

Merged athlete_events.csv with NOC_Regions.csv.
Handled missing values and converted data types for accurate analysis.

**Descriptive Statistics:**

Calculated basic statistics (mean, median, standard deviation) for age, height, and weight.

**Visualization:**

Created histograms, bar charts, and scatter plots to illustrate findings.

**Technical Skills Demonstrated**

Data Manipulation: Used Pandas for data cleaning and merging.
Statistical Analysis: Applied statistical methods for descriptive analysis.
Data Visualization: Employed Matplotlib and Seaborn for visual representation of data.
Python Programming: Developed scripts to automate data analysis tasks.

**Skills and Tools Used**
Data Manipulation: Pandas
Statistical Analysis: Python
Visualization: Matplotlib, Seaborn
Environment: Jupyter Notebook

**Conclusion**
Analyzed and visualized athlete data to identify trends in physical attributes across regions. Demonstrated proficiency in data cleaning, statistical analysis, and visualization.

 **Link to Project:**  [Olympic Athlete Data Analysis ](https://github.com/saeedaFatimah/Portfolio/tree/Project-3-Olympic-Athlete-Data-Analysis)

### [ML Model Classification for the Employee Dataset ]

**Project Overview**
In this project, we predicted employee churn using a dataset with features such as education level, joining year, city, payment tier, age, gender, experience in the current domain, and whether the employee has ever been benched. The target variable was 'LeaveOrNot'.

**Data Preprocessing**

Missing Values: Handled any missing data.
Encoding: Converted categorical variables ('Education', 'City', 'Gender', 'EverBenched') using appropriate encoding techniques.
Scaling: Applied StandardScaler to numerical features.
Exploratory Data Analysis (EDA)
Analyzed distributions and relationships between features.

Key insights on how education, payment tier, and experience affect churn.

**Modeling**

Built models using Logistic Regression, Random Forest, SVM, and KNN.
Evaluated models with accuracy, precision, recall, and F1-score.
Performed hyperparameter tuning for optimization.

**Results**
Best Model: Random Forest with the highest accuracy.
Important Features: 'ExperienceInCurrentDomain', 'Age', and 'PaymentTier'.

**Conclusion**
Effective use of machine learning to predict employee churn, providing insights to help reduce turnover and improve retention strategies.

**Link to Project:**  [ML Classification for the Employee Dataset](https://github.com/saeedaFatimah/Portfolio/tree/Project-4-ML-Model-Classification-for-the-Employee-Dataset)


### [ Hubway Trips Analysis through SQL and Pandas ]

**Objective:** Analyze Hubway bike-sharing trip data to uncover trends and patterns in user behavior.

**Key Activities**

*Data Cleaning and Preparation:*

Loaded data from SQL tables trips and stations.
Cleaned the data by replacing empty strings with NULL values and converting data types appropriately.
Exploratory Data Analysis (EDA):

Analyzed the duration, start and end times, start and end stations, bike numbers, user types, and user demographics (gender and birth date).

*Descriptive Statistics:*

Calculated the number of trips and stations to understand the dataset's scope.
Analyzed trip duration to identify common trip lengths and potential anomalies.

*User Demographics:*

Analyzed user demographics, including gender distribution and age bands.

*Geographic Analysis:*

Mapped trips to states using user zip codes.
Identified the top 5 states with the highest number of rides for registered users

*Data Visualization:*

Created various visualizations to represent the data, such as bar charts for trip counts and demographic distributions.

**Technical Skills Demonstrated**
*SQL:*

Queried and manipulated data in SQL.
Used SQL for data extraction and initial data cleaning steps.

*Python:*

Used Pandas for data manipulation and analysis.
Applied functions to clean and process the data.
Used zipcodes library to map zip codes to state names.

*Data Visualization:*

Created visualizations using Matplotlib and Seaborn to represent findings clearly.
Tools and Technologies Used
SQL
Python
Pandas
Matplotlib & Seaborn
Jupyter Notebook

**Conclusion**
This project analyzed Hubway bike-sharing data to identify trends in user behavior and demographics. The analysis demonstrated proficiency in SQL for data extraction, Python for data manipulation and visualization, and effective communication of findings through visualizations

**Link to Project:**  [Hubway Trips Analysis through SQL and Pandas](https://github.com/saeedaFatimah/Portfolio/tree/Project-5-Hubway-Trips-Analysis-through-SQL-and-Pandas)


### Merchant Market Dashboard

**Objective:**  Create a Power BI dashboard to visualize and analyze merchant market data.

**Key Features of the Dashboard**
*Sales Performance:*

Visualizes overall sales metrics, including total sales, average sales, and sales trends over time.
Breaks down sales by product categories, regions, and time periods to identify top-performing segments.

*Customer Insights:*

Analyzes customer demographics and purchasing behavior.
Segments customers based on purchase frequency, average order value, and lifetime value.

*Product Analysis:*

Examines product performance, highlighting best-selling products and underperformers.
Analyzes inventory levels and turnover rates to optimize stock management.

*Regional Analysis:*

Visualizes sales distribution across different regions.
Identifies regional trends and market opportunities.

*Performance Metrics:*

Key performance indicators (KPIs) such as gross margin, return rates, and customer satisfaction scores.
Compares current performance against targets and historical data.

**Technical Skills Demonstrated**

*Data Visualization:*

Designed interactive and intuitive visualizations using Power BI.
Used various chart types (bar charts, line charts, pie charts, maps) to represent data effectively.

*Data Integration:*

Integrated data from multiple sources (e.g., sales databases, customer records).
Ensured data consistency and accuracy through data cleaning and transformation.

*Dashboard Design:*

Created a user-friendly and visually appealing dashboard layout.
Used filters and drill-down capabilities to allow users to explore data at different levels of detail.

*Tools and Technologies Used*

Power BI: Primary tool for creating the dashboard and visualizations.
Data Sources: Various data sources such as SQL databases, Excel files, and CSV files.
Data Transformation: Power Query for data cleaning and preparation.

**Conclusion**
The Merchant Market dashboard provides comprehensive insights into sales performance, customer behavior, product analysis, and regional trends. It demonstrates advanced skills in data visualization, dashboard design, and data integration, making it a valuable tool for data-driven decision-making. ​

**Link to Project:**  [Merchant Market Dashboard](https://github.com/saeedaFatimah/Portfolio/tree/Project-6--Merchant-Market-Dashboard)


### Linear Regression Analysis for Customer Analytics

**Description:**
In this project, I performed a comprehensive linear regression analysis using a dataset related to customer analytics.

**Key Steps:**

*Data Preparation:*

Loaded and inspected the dataset from a CSV file.
Checked for and handled missing values and duplicates.

*Exploratory Data Analysis (EDA):*

Conducted descriptive statistics and visualized the data using various plots to understand distributions and relationships between variables.

*Feature Engineering:*

Applied label encoding to categorical variables to prepare them for the regression model.

**Model Building:**

Split the data into training and testing sets.
Built a linear regression model using scikit-learn.
Evaluated the model using metrics such as Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared (R²).

*Tools and Libraries Used:*

Pandas
NumPy
Matplotlib
Seaborn
Scipy
Statsmodels
Scikit-learn

**Link to Project:**  [Linear Regression Analysis](https://github.com/saeedaFatimah/Portfolio/tree/Project-7--Linear-Regression-Analysis-for-Customer-Analytics)

### Statistical Hypothesis Tests (Z Test and T test)

**Description:**

This project involved performing statistical hypothesis tests (Z-tests and T-tests) to analyze sample data and draw inferences.

**Key Steps:**

*Confidence Intervals:*

Calculated 85%, 90%, and 95% confidence intervals for the mean monthly rent of apartments in Karachi using sample data.
Analyzed how the confidence intervals change with different confidence levels.

*Hypothesis Testing:*

Used Z-tests and T-tests to compare sample means and proportions.
Visualized the results to aid in interpretation.

*Specific Analyses:*

Calculated Z-scores for different confidence levels and plotted confidence intervals.
Used Python libraries to compute and visualize the confidence intervals and hypothesis test results.

*Tools and Libraries Used:*

Pandas
NumPy
Scipy
Matplotlib
Seaborn

**Link to Project:**  [Statistical Hypothesis Tests (Z Test and T test)](https://github.com/saeedaFatimah/Portfolio/tree/Project-8--Statistical-Hypothesis-Tests-(Z-Test-and-T-test))


### A/B Testing for Advertising Campaign Effectiveness

**Description:**

This project focused on performing A/B tests to determine the effectiveness of different variants in an advertising campaign.

**Key Steps:**

*Data Collection and Preparation:*

Gathered data from surveys conducted at local shopping malls to analyze customer willingness to participate in market research.

*Hypothesis Testing:*

Conducted A/B tests to compare the proportions of customers willing to participate in surveys across different groups.
Used a significance level of 0.01 to test the claim that the proportions are equal.

*Inference and Conclusion:*

Performed statistical tests to derive conclusions from the data.
Documented the findings and provided interpretations in plain English.

*Specific Analyses:*

Used proportions Z-tests to compare categorical values.
Visualized the results to better understand the data and support conclusions.

*Tools and Libraries Used:*

Pandas
NumPy
Scipy
Statsmodels
Matplotlib
Seaborn

**Link to Project:**  [A/B Testing for Advertising Campaign Effectiveness)](https://github.com/saeedaFatimah/Portfolio/tree/Project-9-A/B-Testing-for-Advertising-Campaign-Effectiveness)

## How to Use

To run any of the projects locally, follow these steps:

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/portfolio.git
   cd portfolio
